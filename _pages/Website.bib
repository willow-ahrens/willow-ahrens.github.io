
@misc{ahrens_optimal_2021,
	title = {On {Optimal} {Partitioning} {For} {Sparse} {Matrices} {In} {Variable} {Block} {Row} {Format}},
	url = {http://arxiv.org/abs/2005.12414},
	doi = {10.48550/arXiv.2005.12414},
	abstract = {The Variable Block Row (VBR) format is an influential blocked sparse matrix format designed for matrices with shared sparsity structure between adjacent rows and columns. VBR groups adjacent rows and columns, storing the resulting blocks that contain nonzeros in a dense format. This reduces the memory footprint and enables optimizations such as register blocking and instruction-level parallelism. Existing approaches use heuristics to determine which rows and columns should be grouped together. We show that finding the optimal grouping of rows and columns for VBR is NP-hard under several reasonable cost models. In light of this finding, we propose a 1-dimensional variant of VBR, called 1D-VBR, which achieves better performance than VBR by only grouping rows. We describe detailed cost models for runtime and memory consumption. Then, we describe a linear time dynamic programming solution for optimally grouping the rows for 1D-VBR format. We extend our algorithm to produce a heuristic VBR partitioner which alternates between optimally partitioning rows and columns, assuming the columns or rows to be fixed, respectively. Our alternating heuristic produces VBR matrices with the smallest memory footprint of any partitioner we tested.},
	urldate = {2022-08-10},
	publisher = {arXiv},
	author = {Ahrens, Willow and Boman, Erik G.},
	month = may,
	year = {2021},
	note = {arXiv:2005.12414 [cs]},
	keywords = {Computer Science - Data Structures and Algorithms},
	file = {Ahrens and Boman - 2020 - On Optimal Partitioning For Sparse Matrices In Var.pdf:/Users/willow/Zotero/storage/RGQGCZKD/Ahrens and Boman - 2020 - On Optimal Partitioning For Sparse Matrices In Var.pdf:application/pdf;arXiv Fulltext PDF:/Users/willow/Zotero/storage/BWHWXSNS/Ahrens and Boman - 2021 - On Optimal Partitioning For Sparse Matrices In Var.pdf:application/pdf;arXiv.org Snapshot:/Users/willow/Zotero/storage/E63KTTB9/2005.html:text/html},
}

@inproceedings{ahrens_autoscheduling_2022,
	address = {New York, NY, USA},
	series = {{PLDI}},
	title = {Autoscheduling for sparse tensor algebra with an asymptotic cost model},
	copyright = {All rights reserved},
	isbn = {978-1-4503-9265-5},
	url = {https://doi.org/10.1145/3519939.3523442},
	doi = {10.1145/3519939.3523442},
	abstract = {While loop reordering and fusion can make big impacts on the constant-factor performance of dense tensor programs, the effects on sparse tensor programs are asymptotic, often leading to orders of magnitude performance differences in practice. Sparse tensors also introduce a choice of compressed storage formats that can have asymptotic effects. Research into sparse tensor compilers has led to simplified languages that express these tradeoffs, but the user is expected to provide a schedule that makes the decisions. This is challenging because schedulers must anticipate the interaction between sparse formats, loop structure, potential sparsity patterns, and the compiler itself. Automating this decision making process stands to finally make sparse tensor compilers accessible to end users. We present, to the best of our knowledge, the first automatic asymptotic scheduler for sparse tensor programs. We provide an approach to abstractly represent the asymptotic cost of schedules and to choose between them. We narrow down the search space to a manageably small Pareto frontier of asymptotically non-dominating kernels. We test our approach by compiling these kernels with the TACO sparse tensor compiler and comparing them with those generated with the default TACO schedules. Our results show that our approach reduces the scheduling space by orders of magnitude and that the generated kernels perform asymptotically better than those generated using the default schedules.},
	urldate = {2022-07-21},
	booktitle = {Proceedings of the 43rd {ACM} {SIGPLAN} {International} {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {Association for Computing Machinery},
	author = {Ahrens, Willow and Kjolstad, Fredrik and Amarasinghe, Saman},
	month = jun,
	year = {2022},
	keywords = {Asymptotic Analysis, Automatic Scheduling, Compilers, Conjunctive Query Containment, Query Optimization, Sparse Tensors},
	pages = {269--285},
	file = {Full Text PDF:/Users/willow/Zotero/storage/V6PAKBZT/Ahrens et al. - 2022 - Autoscheduling for sparse tensor algebra with an a.pdf:application/pdf;Full Text PDF:/Users/willow/Zotero/storage/QDCN3ULM/Ahrens et al. - 2022 - Autoscheduling for sparse tensor algebra with an a.pdf:application/pdf},
}

@mastersthesis{ahrens_parallel_2019,
	title = {A {Parallel} {Fill} {Estimation} {Algorithm} for {Sparse} {Matrices} and {Tensors} in {Blocked} {Formats}},
	copyright = {MIT theses are protected by copyright. They may be viewed, downloaded, or printed from this source but further reproduction or distribution in any format is prohibited without written permission.},
	url = {https://dspace.mit.edu/handle/1721.1/121653},
	abstract = {Many sparse matrices and tensors from a variety of applications, such as finite element methods and computational chemistry, have a natural aligned rectangular nonzero block structure. Researchers have designed high-performance blocked sparse operations which can take advantage of this sparsity structure to reduce the complexity of storing the locations of nonzeros. The performance of a blocked sparse operation depends on how well the block size reflects the structure of nonzeros in the tensor. Sparse tensor structure is generally unknown until runtime, so block size selection must be efficient. The fill is a quantity which, for some block size, relates the number of nonzero blocks to the number of nonzeros. Many performance models use the fill to help choose a block size. However, the fill is expensive to compute exactly.  We present a sampling-based algorithm called Phil to estimate the fill of sparse matrices and tensors in any format. We provide theoretical guarantees for sparse matrices and tensors, and experimental results for matrices. The existing state-of-the-art fill estimation algorithm, which we will call OSKI, runs in time linear in the number of elements in the tensor. The number of samples Phil needs to compute a fill estimate is unrelated to the number of nonzeros and depends only on the order (number of dimensions) of the tensor, desired accuracy of the estimate, desired probability of achieving this accuracy, and number of considered block sizes. We parallelize Phil, and refer to the parallel implementation as PPhil. We compare Phil, PPhil, and OSKI on a suite of 42 matrices. On average, PPhil was able to produce a fill estimate in 1.3810 times the time it took to compute one sparse matrix vector multiply, which was 61.176 times faster than OSKI. The maximum error generated by Phil was 0.0480, while OSKI sometimes produced estimates with a complete loss of accuracy. Finally, we find that Phil and OSKI produce comparable speedups in multicore blocked sparse matrix-vector multiplication (SpMV) when the block size was chosen using fill estimates in a model due to Vuduc et al.  Much of the work presented in this thesis appears in ["A Fill Estimation Algorithm for Sparse Matrices and Tensors in Blocked Formats," in 2018 IEEE International Parallel and Distributed Processing Symposium (IPDPS), May 2018, pp. 546-556.], a paper coauthored with Helen Xu and Nicholas Schiefer. The parallel algorithm PPhil and its implementation are novel contributions of this thesis. Helen's masters thesis is also based on the IPDPS publication, and adds additional test matrices ["Fill Estimation for Blocked Sparse Matrices and Tensors," Master's thesis, Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, Jun. 2018.].},
	language = {eng},
	urldate = {2019-11-20},
	school = {Massachusetts Institute of Technology},
	author = {Ahrens, Willow},
	year = {2019},
	file = {Ahrens - 2019 - A Parallel Fill Estimation Algorithm for Sparse Ma.pdf:/Users/willow/Zotero/storage/TY5TLVGA/Ahrens - 2019 - A Parallel Fill Estimation Algorithm for Sparse Ma.pdf:application/pdf;Snapshot:/Users/willow/Zotero/storage/8Z8D3RH5/121653.html:text/html},
}

@article{tumblin_parallel_2015,
	title = {Parallel {Compact} {Hash} {Algorithms} for {Computational} {Meshes}},
	volume = {37},
	copyright = {All rights reserved},
	issn = {1064-8275},
	url = {https://epubs.siam.org/doi/10.1137/13093371X},
	doi = {10.1137/13093371X},
	abstract = {We employ compact hashing and the discrete properties of computational meshes to optimize spatial operations in scientific computing applications. Our target is to develop highly parallel compact hashing methods suitable for the fine-grained parallelism of GPU and MIC architectures that will scale to the next generation of computing systems. As a model, we apply spatial hashing methods to the problem of determining neighbor elements in adaptive mesh refinement (AMR) schemes. By applying memory savings techniques, we extend the perfect spatial hash algorithm to a compact hash by compressing the resulting sparse data structures. Using compact hashing and specific memory optimizations, we increase the range of problems that can benefit from our ideal \$O(n)\$ algorithms. The spatial hash methods are tested and compared across a variety of architectures on both a randomly generated sample mesh and an existing cell-based AMR shallow-water hydrodynamics scheme. We demonstrate consistent speed-up and increased performance across every device tested and explore the ubiquitous application of spatial hashing in scientific computing.},
	number = {1},
	urldate = {2018-06-14},
	journal = {SIAM J. Sci. Comput.},
	author = {Tumblin, R. and Ahrens, W. and Hartse, S. and Robey, R.},
	month = jan,
	year = {2015},
	pages = {C31--C53},
	file = {Tumblin et al. - 2015 - Parallel Compact Hash Algorithms for Computational.pdf:/Users/willow/Zotero/storage/E2RVUDBL/Tumblin et al. - 2015 - Parallel Compact Hash Algorithms for Computational.pdf:application/pdf},
}

@misc{ahrens_contiguous_2021,
	title = {Contiguous {Graph} {Partitioning} {For} {Optimal} {Total} {Or} {Bottleneck} {Communication}},
	copyright = {All rights reserved},
	url = {http://arxiv.org/abs/2007.16192},
	abstract = {Graph partitioning schedules parallel calculations like sparse matrix-vector multiply (SpMV). We consider contiguous partitions, where the \$m\$ rows (or columns) of a sparse matrix with \$N\$ nonzeros are split into \$K\$ parts without reordering. We propose the first near-linear time algorithms for several graph partitioning problems in the contiguous regime. Traditional objectives such as the simple edge cut, hyperedge cut, or hypergraph connectivity minimize the total cost of all parts under a balance constraint. Our total partitioners use \$O(Km + N)\$ space. They run in \$O((Km{\textbackslash}log(m) + N){\textbackslash}log(N))\$ time, a significant improvement over prior \$O(K(m{\textasciicircum}2 + N))\$ time algorithms due to Kernighan and Grandjean et. al. Bottleneck partitioning minimizes the maximum cost of any part. We propose a new bottleneck cost which reflects the sum of communication and computation on each part. Our bottleneck partitioners use linear space. The exact algorithm runs in linear time when \$K{\textasciicircum}2\$ is \$O(N{\textasciicircum}C)\$ for \$C {\textless} 1\$. Our \$(1 + {\textbackslash}epsilon)\$-approximate algorithm runs in linear time when \$K{\textbackslash}log(c\_\{high\}/(c\_\{low\}{\textbackslash}epsilon))\$ is \$O(N{\textasciicircum}C)\$ for \$C {\textless} 1\$, where \$c\_\{high\}\$ and \$c\_\{low\}\$ are upper and lower bounds on the optimal cost. We also propose a simpler \$(1 + {\textbackslash}epsilon)\$-approximate algorithm which runs in a factor of \${\textbackslash}log(c\_\{high\}/(c\_\{low\}{\textbackslash}epsilon))\$ from linear time. We empirically demonstrate that our algorithms efficiently produce high-quality contiguous partitions on a test suite of \$42\$ test matrices. When \$K = 8\$, our hypergraph connectivity partitioner achieved a speedup of \$53{\textbackslash}times\$ (mean \$15.1{\textbackslash}times\$) over prior algorithms. The mean runtime of our bottleneck partitioner was \$5.15\$ SpMVs.},
	urldate = {2021-09-17},
	publisher = {arXiv},
	author = {Ahrens, Willow},
	month = jun,
	year = {2021},
	note = {arXiv: 2007.16192},
	keywords = {Computer Science - Data Structures and Algorithms},
	file = {Ahrens - 2021 - Contiguous Graph Partitioning For Optimal Total Or.pdf:/Users/willow/Zotero/storage/5R2L7MKH/Ahrens - 2021 - Contiguous Graph Partitioning For Optimal Total Or.pdf:application/pdf;arXiv.org Snapshot:/Users/willow/Zotero/storage/ES6JQKHR/2007.html:text/html;arXiv.org Snapshot:/Users/willow/Zotero/storage/BS2D5YL5/2007.html:text/html},
}

@techreport{ahrens_efficient_2016,
	title = {Efficient {Reproducible} {Floating} {Point} {Summation} and {BLAS}},
	copyright = {All rights reserved},
	url = {https://www2.eecs.berkeley.edu/Pubs/TechRpts/2016/EECS-2016-121.html},
	abstract = {We define reproducibility to mean getting bitwise identical results from multiple runs of the same program, perhaps with different hardware resources or other changes that should ideally not change the answer. Many users depend on reproducibility for debugging or correctness. However, dynamic scheduling of parallel computing resources, combined with nonassociativity of floating point addition, makes attaining reproducibility a challenge even for simple operations like summing a vector of numbers, or more complicated operations like the Basic Linear Algebra Subprograms (BLAS). We describe an algorithm that computes a reproducible sum of floating point numbers, independent of the order of summation. The algorithm depends only on a subset of the IEEE Floating Point Standard 754-2008. It is communication-optimal, in the sense that it does just one pass over the data in the sequential case, or one reduction operation in the parallel case, requiring an “accumulator” represented by just 6 floating point words (more can be used if higher precision is desired). The arithmetic cost with a 6-word accumulator is 7n floating point additions to sum n words, and (in IEEE double precision) the final error bound can be up to 10⁽-8) times smaller than the error bound for conventional summation. We describe the basic summation algorithm, the software infrastructure used to build reproducible BLAS (ReproBLAS), and performance results. For example, when computing the dot product of 4096 double precision floating point numbers, we get a 4x slowdown compared to Intel Math Kernel Library (MKL) running on an Intel Core i7-2600 CPU operating at 3.4 GHz and 256 KB L2 Cache.},
	number = {UCB/EECS-2016-121},
	institution = {EECS Department, University of California, Berkeley},
	author = {Ahrens, W. and Demmel, J. and Nguyen, H. D.},
	month = jun,
	year = {2016},
	file = {Ahrens et al. - 2016 - Efficient Reproducible Floating Point Summation an.pdf:/Users/willow/Zotero/storage/YHBBXRQB/Ahrens et al. - 2016 - Efficient Reproducible Floating Point Summation an.pdf:application/pdf},
}

@inproceedings{ahrens_fill_2018,
	series = {{IPDPS}},
	title = {A {Fill} {Estimation} {Algorithm} for {Sparse} {Matrices} and {Tensors} in {Blocked} {Formats}},
	copyright = {All rights reserved},
	url = {https://doi.org/10.1109/IPDPS.2018.00064},
	doi = {10.1109/IPDPS.2018.00064},
	abstract = {Many sparse matrices and tensors from a variety of applications, such as finite element methods and computational chemistry, have a natural aligned rectangular nonzero block structure. Researchers have designed high-performance blocked sparse operations which can take advantage of this sparsity structure to reduce the complexity of storing the locations of nonzeros. The performance of a blocked sparse operation depends on how well the block size reflects the structure of nonzeros in the tensor. Sparse tensor structure is generally unknown until runtime, so block size selection must be efficient. The fill is a quantity which, for some block size, relates the number of nonzero blocks to the number of nonzeros. Many performance models use the fill to help choose a block size. However, the fill is expensive to compute exactly. We present a sampling-based algorithm called Phil to estimate the fill of sparse matrices and tensors in any format. We provide theoretical guarantees for sparse matrices and tensors, and experimental results for matrices. The existing state-of-the-art fill estimation algorithm, which we will call OSKI, runs in time linear in the number of elements in the tensor. The number of samples Phil needs to compute a fill estimate is unrelated to the number of nonzeros and depends only on the order (number of dimensions) of the tensor, desired accuracy of the estimate, desired probability of achieving this accuracy, and number of considered block sizes. We compare Phil and OSKI on a suite of 42 matrices. On most inputs, Phil estimates the fill at least 2 times faster and often more than 20 times faster than OSKI. Phil consistently produced accurate estimates; in all cases that we tested Phil was faster and/or more accurate than OSKI. Finally, we find that Phil and OSKI produce comparable speedups in multicore blocked sparse matrix-vector multiplication (SpMV) when the block size was chosen using fill estimates in a model due to Vuduc et al.},
	booktitle = {2018 {IEEE} {International} {Parallel} and {Distributed} {Processing} {Symposium} ({IPDPS})},
	publisher = {IPDPS},
	author = {Ahrens, Willow and Xu, Helen and Schiefer, Nicholas},
	month = may,
	year = {2018},
	keywords = {Autotuning, block size selection, Block Size Selection, Block Sparse, blocked formats, blocked sparse operation, Chemistry, complexity, Complexity theory, computational chemistry, Estimation, Fill Estimation, fill estimation algorithm, finite element analysis, finite element methods, Kernel, matrix multiplication, multicore blocked sparse matrix-vector multiplication, natural aligned rectangular nonzero block structure, Numerical Linear Algebra, OSKI, Performance Engineering, Performance Model, Phil, probability, Randomized Algorithm, Runtime, Sampling Algorithm, sampling methods, sampling-based algorithm, sparse matrices, Sparse matrices, Sparse Matrix, Sparse Tensor, sparse tensor structure, SpMV, Tensile stress, tensors, vectors},
	pages = {546--556},
	file = {Ahrens et al. - 2018 - A Fill Estimation Algorithm for Sparse Matrices an.pdf:/Users/willow/Zotero/storage/6LQF6T68/Ahrens et al. - 2018 - A Fill Estimation Algorithm for Sparse Matrices an.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/willow/Zotero/storage/QKANLUGL/8425208.html:text/html},
}

@misc{ahrens_late_2018,
	title = {{LATE} {Ain}'{T} {Earley}: {A} {Faster} {Parallel} {Earley} {Parser}},
	copyright = {All rights reserved},
	shorttitle = {{LATE} {Ain}'{T} {Earley}},
	url = {https://arxiv.org/abs/1807.05642},
	abstract = {We present the LATE algorithm, an asynchronous variant of the Earley algorithm for parsing context-free grammars. The Earley algorithm is naturally task-based, but is difficult to parallelize because of dependencies between the tasks. We present the LATE algorithm, which uses additional data structures to maintain information about the state of the parse so that work items may be processed in any order. This property allows the LATE algorithm to be sped up using task parallelism. We show that the LATE algorithm can achieve a 120x speedup over the Earley algorithm on a natural language task.},
	urldate = {2019-11-29},
	publisher = {arXiv},
	author = {Ahrens, Willow and Feser, John and Hui, Robin},
	month = jul,
	year = {2018},
	note = {arXiv: 1807.05642},
	keywords = {Computer Science - Computation and Language, Computer Science - Distributed, Parallel, and Cluster Computing},
	file = {Ahrens et al. - 2018 - LATE Ain'T Earley A Faster Parallel Earley Parser.html:/Users/willow/Zotero/storage/MWW6RXI5/Ahrens et al. - 2018 - LATE Ain'T Earley A Faster Parallel Earley Parser.html:text/html;Ahrens et al. - 2018 - LATE Ain'T Earley A Faster Parallel Earley Parser.pdf:/Users/willow/Zotero/storage/5ATBZBVX/Ahrens et al. - 2018 - LATE Ain'T Earley A Faster Parallel Earley Parser.pdf:application/pdf},
}

@inproceedings{kjolstad_tensor_2019,
	series = {{CGO}},
	title = {Tensor {Algebra} {Compilation} with {Workspaces}},
	copyright = {All rights reserved},
	url = {https://doi.org/10.1109/CGO.2019.8661185},
	doi = {10.1109/CGO.2019.8661185},
	abstract = {This paper shows how to extend sparse tensor algebra compilers to introduce temporary tensors called workspaces to avoid inefficient sparse data structures accesses. We develop an intermediate representation (IR) for tensor operations called concrete index notation that specifies when sub-computations occur and where they are stored. We then describe the workspace transformation in this IR, how to programmatically invoke it, and how the IR is compiled to sparse code. Finally, we show how the transformation can be used to optimize sparse tensor kernels, including sparse matrix multiplication, sparse tensor addition, and the matricized tensor times Khatri-Rao product (MTTKRP). Our results show that the workspace transformation brings the performance of these kernels on par with hand-optimized implementations. For example, we improve the performance of MTTKRP with dense output by up to 35\%, and enable generating sparse matrix multiplication and MTTKRP with sparse output, neither of which were supported by prior tensor algebra compilers.},
	booktitle = {2019 {IEEE}/{ACM} {International} {Symposium} on {Code} {Generation} and {Optimization} ({CGO})},
	publisher = {CGO},
	author = {Kjolstad, Fredrik and Ahrens, Willow and Kamil, Shoaib and Amarasinghe, Saman},
	month = feb,
	year = {2019},
	keywords = {Algebra, Arrays, code optimization, compiler IR, concrete index notation, data structures, Indexes, intermediate representation, Kernel, matricized tensor times Khatri-Rao product, matrix decomposition, matrix multiplication, program compilers, sparse data structures, sparse matrices, Sparse matrices, sparse matrix multiplication, sparse tensor addition, sparse tensor algebra, sparse tensor algebra compilers, sparse tensor kernels, temporaries, tensors, workspaces},
	pages = {180--192},
	file = {Full Text PDF:/Users/willow/Zotero/storage/FCYUD2HP/Kjolstad et al. - 2019 - Tensor algebra compilation with workspaces.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/willow/Zotero/storage/SAZD6MM9/8661185.html:text/html;Kjolstad et al. - 2019 - Tensor Algebra Compilation with Workspaces.pdf:/Users/willow/Zotero/storage/K5Z25DFE/Kjolstad et al. - 2019 - Tensor Algebra Compilation with Workspaces.pdf:application/pdf},
}

@article{ahrens_algorithms_2020,
	title = {Algorithms for {Efficient} {Reproducible} {Floating} {Point} {Summation}},
	volume = {46},
	copyright = {All rights reserved},
	issn = {0098-3500},
	url = {https://doi.org/10.1145/3389360},
	doi = {10.1145/3389360},
	abstract = {We define “reproducibility” as getting bitwise identical results from multiple runs of the same program, perhaps with different hardware resources or other changes that should not affect the answer. Many users depend on reproducibility for debugging or correctness. However, dynamic scheduling of parallel computing resources, combined with nonassociative floating point addition, makes reproducibility challenging even for summation, or operations like the BLAS. We describe a “reproducible accumulator” data structure (the “binned number”) and associated algorithms to reproducibly sum binary floating point numbers, independent of summation order. We use a subset of the IEEE Floating Point Standard 754-2008 and bitwise operations on the standard representations in memory. Our approach requires only one read-only pass over the data, and one reduction in parallel, using a 6-word reproducible accumulator (more words can be used for higher accuracy), enabling standard tiling optimization techniques. Summing n words with a 6-word reproducible accumulator requires approximately 9n floating point operations (arithmetic, comparison, and absolute value) and approximately 3n bitwise operations. The final error bound with a 6-word reproducible accumulator and our default settings can be up to 229 times smaller than the error bound for conventional (recursive) summation on ill-conditioned double-precision inputs.},
	number = {3},
	urldate = {2020-07-22},
	journal = {ACM Trans. Math. Softw.},
	author = {Ahrens, Willow and Demmel, James and Nguyen, Hong Diep},
	month = jul,
	year = {2020},
	keywords = {binned number, binned summation, computer arithmetic, floating point number, floating point summation, parallel, reproducibility, Reproducible summation, summation},
	pages = {22:1--22:49},
	file = {Ahrens et al. - 2020 - Algorithms for Efficient Reproducible Floating Poi.pdf:/Users/willow/Zotero/storage/B9P73339/Ahrens et al. - 2020 - Algorithms for Efficient Reproducible Floating Poi.pdf:application/pdf;Full Text PDF:/Users/willow/Zotero/storage/ZMN44A3B/Ahrens et al. - 2020 - Algorithms for Efficient Reproducible Floating Poi.pdf:application/pdf;Full Text PDF:/Users/willow/Zotero/storage/GMNUWIGM/Ahrens et al. - 2020 - Algorithms for Efficient Reproducible Floating Poi.pdf:application/pdf},
}

@misc{mueller_sparse_2020,
	title = {Sparse {Tensor} {Transpositions}},
	copyright = {All rights reserved},
	url = {https://arxiv.org/abs/2005.10427},
	abstract = {We present a new algorithm for transposing sparse tensors called Quesadilla.
The algorithm converts the sparse tensor data structure to a list of
coordinates and sorts it with a fast multi-pass radix algorithm that exploits
knowledge of the requested transposition and the tensors input partial
coordinate ordering to provably minimize the number of parallel partial sorting
passes. We evaluate both a serial and a parallel implementation of Quesadilla
on a set of 19 tensors from the FROSTT collection, a set of tensors taken from
scientific and data analytic applications. We compare Quesadilla and a
generalization, Top-2-sadilla to several state of the art approaches, including
the tensor transposition routine used in the SPLATT tensor factorization
library. In serial tests, Quesadilla was the best strategy for 60\% of all
tensor and transposition combinations and improved over SPLATT by at least 19\%
in half of the combinations. In parallel tests, at least one of Quesadilla or
Top-2-sadilla was the best strategy for 52\% of all tensor and transposition
combinations.},
	language = {en},
	urldate = {2020-08-03},
	publisher = {arXiv},
	author = {Mueller, Suzanne and Ahrens, Willow and Chou, Stephen and Kjolstad, Fredrik and Amarasinghe, Saman},
	month = may,
	year = {2020},
	file = {Mueller et al. - 2020 - Sparse Tensor Transpositions.pdf:/Users/willow/Zotero/storage/UGNXS6QR/Mueller et al. - 2020 - Sparse Tensor Transpositions.pdf:application/pdf;Snapshot:/Users/willow/Zotero/storage/4NNB6QDG/2005.html:text/html},
}

@inproceedings{mueller_sparse_2020-1,
	address = {Virtual Event, USA},
	series = {{SPAA}},
	title = {Sparse {Tensor} {Transpositions}: {Brief} {Announcement}},
	copyright = {All rights reserved},
	isbn = {978-1-4503-6935-0},
	url = {https://doi.org/10.1145/3350755.3400245},
	doi = {10.1145/3350755.3400245},
	abstract = {We present a new algorithm for transposing sparse tensors called Quesadilla. The algorithm converts the sparse tensor data structure to a list of coordinates and sorts it with a fast multi-pass radix algorithm that exploits knowledge of the requested transposition and the tensors input partial coordinate ordering to provably minimize the number of parallel partial sorting passes. We evaluate both a serial and a parallel implementation of Quesadilla on a set of 19 tensors from the FROSTT collection, a set of tensors taken from scientific and data analytic applications. We compare Quesadilla and a generalization, Top-2-sadilla to several state of the art approaches, including the tensor transposition routine used in the SPLATT tensor factorization library. In serial tests, Quesadilla was the best strategy for 60\% of all tensor and transposition combinations and improved over SPLATT by at least 19\% in half of the combinations. In parallel tests, at least one of Quesadilla or Top-2-sadilla was the best strategy for 52\% of all tensor and transposition combinations.},
	urldate = {2020-08-03},
	booktitle = {Proceedings of the 32nd {ACM} {Symposium} on {Parallelism} in {Algorithms} and {Architectures}},
	publisher = {Association for Computing Machinery},
	author = {Mueller, Suzanne and Ahrens, Willow and Chou, Stephen and Kjolstad, Fredrik and Amarasinghe, Saman},
	month = jul,
	year = {2020},
	keywords = {COO, radix sort, sorting, sparse tensors, transposition},
	pages = {559--561},
	file = {Mueller et al. - 2020 - Sparse Tensor Transpositions.pdf:/Users/willow/Zotero/storage/3F3PPKD5/Mueller et al. - 2020 - Sparse Tensor Transpositions.pdf:application/pdf},
}

@inproceedings{ahrens_looplets_2023,
	address = {New York, NY, USA},
	series = {{CGO}},
	title = {Looplets: {A} {Language} for {Structured} {Coiteration}},
	isbn = {9798400701016},
	shorttitle = {Looplets},
	doi = {10.1145/3579990.3580020},
	abstract = {Real world arrays often contain underlying structure, such as sparsity, runs of repeated values, or symmetry. Specializing for structure yields significant speedups. But automatically generating efficient code for structured data is challenging, especially when arrays with different structure interact. We show how to abstract over array structures so that the compiler can generate code to coiterate over any combination of them. Our technique enables new array formats (such as 1DVBL for irregular clustered sparsity), new iteration strategies (such as galloping intersections), and new operations over structured data (such as concatenation or convolution).},
	urldate = {2023-04-03},
	booktitle = {Proceedings of the 21st {ACM}/{IEEE} {International} {Symposium} on {Code} {Generation} and {Optimization}},
	publisher = {Association for Computing Machinery},
	author = {Ahrens, Willow and Donenfeld, Daniel and Kjolstad, Fredrik and Amarasinghe, Saman},
	month = feb,
	year = {2023},
	keywords = {Array, Coiteration, Compressed, Sparse, Tensor},
	pages = {41--54},
	file = {Full Text PDF:/Users/willow/Zotero/storage/HUBGW7N9/Ahrens et al. - 2023 - Looplets A Language for Structured Coiteration.pdf:application/pdf;Full Text PDF:/Users/willow/Zotero/storage/82C5H8A5/Ahrens et al. - 2023 - Looplets A Language for Structured Coiteration.pdf:application/pdf},
}

@misc{ahrens_finch_2024,
	title = {Finch: {Sparse} and {Structured} {Array} {Programming} with {Control} {Flow}},
	shorttitle = {Finch},
	url = {http://arxiv.org/abs/2404.16730},
	abstract = {From FORTRAN to NumPy, arrays have revolutionized how we express computation. However, arrays in these, and almost all prominent systems, can only handle dense rectilinear integer grids. Real world arrays often contain underlying structure, such as sparsity, runs of repeated values, or symmetry. Support for structured data is fragmented and incomplete. Existing frameworks limit the array structures and program control flow they support to better simplify the problem. In this work, we propose a new programming language, Finch, which supports both flexible control flow and diverse data structures. Finch facilitates a programming model which resolves the challenges of computing over structured arrays by combining control flow and data structures into a common representation where they can be co-optimized. Finch automatically specializes control flow to data so that performance engineers can focus on experimenting with many algorithms. Finch supports a familiar programming language of loops, statements, ifs, breaks, etc., over a wide variety of array structures, such as sparsity, run-length-encoding, symmetry, triangles, padding, or blocks. Finch reliably utilizes the key properties of structure, such as structural zeros, repeated values, or clustered non-zeros. We show that this leads to dramatic speedups in operations such as SpMV and SpGEMM, image processing, graph analytics, and a high-level tensor operator fusion interface.},
	urldate = {2024-04-26},
	publisher = {arXiv},
	author = {Ahrens, Willow and Collin, Teodoro Fields and Patel, Radha and Deeds, Kyle and Hong, Changwan and Amarasinghe, Saman},
	month = apr,
	year = {2024},
	note = {arXiv:2404.16730 [cs]},
	keywords = {Computer Science - Mathematical Software},
	file = {arXiv Fulltext PDF:/Users/willow/Zotero/storage/CPYNA6Q6/Ahrens et al. - 2024 - Finch Sparse and Structured Array Programming wit.pdf:application/pdf;arXiv.org Snapshot:/Users/willow/Zotero/storage/QZYX6PMS/2404.html:text/html},
}

@misc{won_continuous_2024,
	title = {The {Continuous} {Tensor} {Abstraction}: {Where} {Indices} are {Real}},
	shorttitle = {The {Continuous} {Tensor} {Abstraction}},
	url = {http://arxiv.org/abs/2407.01742},
	doi = {10.48550/arXiv.2407.01742},
	abstract = {This paper introduces the continuous tensor abstraction, allowing indices to take real-number values (e.g., A[3.14]), and provides a continuous loop construct that iterates over the infinitely large set of real numbers. This paper expands the existing tensor abstraction to include continuous tensors that exhibit a piecewise-constant property, enabling the transformation of an infinite amount of computation into a finite amount. Additionally, we present a new tensor format abstraction for storing continuous tensors and a code generation technique that automatically generates kernels for the continuous tensor abstraction. Our approach introduces a novel method for loop-level reasoning in domains like computational geometry and computer graphics, traditionally unexplored in tensor programming models. Our approach demonstrates comparable performance to hand-optimized kernels in leading libraries across diverse applications. Compared to hand-implemented libraries on a CPU, our compiler-based implementation achieves an average speedup of 9.20x on 2D radius search with {\textasciitilde}100x fewer lines of code (LoC), 1.22x on genomic interval overlapping queries (with {\textasciitilde}26x LoC saving), and 1.69x on trilinear interpolation in Neural Radiance Field (with {\textasciitilde}9x LoC saving).},
	urldate = {2024-07-12},
	publisher = {arXiv},
	author = {Won, Jaeyeon and Ahrens, Willow and Emer, Joel S. and Amarasinghe, Saman},
	month = jul,
	year = {2024},
	note = {arXiv:2407.01742 [cs]},
	keywords = {Computer Science - Programming Languages},
	file = {arXiv Fulltext PDF:/Users/willow/Zotero/storage/I47NNMW5/Won et al. - 2024 - The Continuous Tensor Abstraction Where Indices a.pdf:application/pdf;arXiv.org Snapshot:/Users/willow/Zotero/storage/JJ287QES/2407.html:text/html;Won et al. - 2024 - The Continuous Tensor Abstraction Where Indices a.pdf:/Users/willow/Zotero/storage/KNC6C37B/Won et al. - 2024 - The Continuous Tensor Abstraction Where Indices a.pdf:application/pdf},
}

@misc{patel_systec_2024,
	title = {{SySTeC}: {A} {Symmetric} {Sparse} {Tensor} {Compiler}},
	shorttitle = {{SySTeC}},
	url = {http://arxiv.org/abs/2406.09266},
	doi = {10.48550/arXiv.2406.09266},
	abstract = {Symmetric and sparse tensors arise naturally in many domains including linear algebra, statistics, physics, chemistry, and graph theory. Symmetric tensors are equal to their transposes, so in the \$n\$-dimensional case we can save up to a factor of \$n!\$ by avoiding redundant operations. Sparse tensors, on the other hand, are mostly zero, and we can save asymptotically by processing only nonzeros. Unfortunately, specializing for both symmetry and sparsity at the same time is uniquely challenging. Optimizing for symmetry requires consideration of \$n!\$ transpositions of a triangular kernel, which can be complex and error prone. Considering multiple transposed iteration orders and triangular loop bounds also complicates iteration through intricate sparse tensor formats. Additionally, since each combination of symmetry and sparse tensor formats requires a specialized implementation, this leads to a combinatorial number of cases. A compiler is needed, but existing compilers cannot take advantage of both symmetry and sparsity within the same kernel. In this paper, we describe the first compiler which can automatically generate symmetry-aware code for sparse or structured tensor kernels. We introduce a taxonomy for symmetry in tensor kernels, and show how to target each kind of symmetry. Our implementation demonstrates significant speedups ranging from 1.36x for SSYMV to 30.4x for a 5-dimensional MTTKRP over the non-symmetric state of the art.},
	urldate = {2024-07-12},
	publisher = {arXiv},
	author = {Patel, Radha and Ahrens, Willow and Amarasinghe, Saman},
	month = jun,
	year = {2024},
	note = {arXiv:2406.09266 [cs]},
	keywords = {Computer Science - Mathematical Software},
	file = {arXiv Fulltext PDF:/Users/willow/Zotero/storage/XSIH7KW8/Patel et al. - 2024 - SySTeC A Symmetric Sparse Tensor Compiler.pdf:application/pdf;arXiv.org Snapshot:/Users/willow/Zotero/storage/LQZKLW28/2406.html:text/html},
}

@article{gladshtein_mechanised_2024,
	title = {Mechanised {Hypersafety} {Proofs} about {Structured} {Data}},
	volume = {8},
	url = {https://dl.acm.org/doi/10.1145/3656403},
	doi = {10.1145/3656403},
	abstract = {Arrays are a fundamental abstraction to represent collections of data. It is often possible to exploit structural properties of the data stored in an array (e.g., repetition or sparsity) to develop a specialised representation optimised for space efficiency. Formally reasoning about correctness of manipulations with such structured data is challenging, as they are often composed of multiple loops with non-trivial invariants.   In this work, we observe that specifications for structured data manipulations can be phrased as hypersafety properties, i.e., predicates that relate traces of k programs. To turn this observation into an effective verification methodology, we developed the Logic for Graceful Tensor Manipulation (LGTM), a new Hoare-style relational separation logic for specifying and verifying computations over structured data. The key enabling idea of LGTM is that of parametrised hypersafety specifications that allow the number k of the program components to depend on the program variables. We implemented LGTM as a foundational embedding into Coq, mechanising its rules, meta-theory, and the proof of soundness. Furthermore, we developed a library of domain-specific tactics that automate computer-aided hypersafety reasoning, resulting in pleasantly short proof scripts that enjoy a high degree of reuse. We argue for the effectiveness of relational reasoning about structured data in LGTM by specifying and mechanically proving correctness of 13 case studies including computations on compressed arrays and efficient operations over multiple kinds of sparse tensors.},
	urldate = {2024-08-22},
	journal = {PLDI},
	author = {Gladshtein, Vladimir and Zhao, Qiyuan and Ahrens, Willow and Amarasinghe, Saman and Sergey, Ilya},
	month = jun,
	year = {2024},
	keywords = {Computer Science - Logic in Computer Science, Computer Science - Programming Languages},
	pages = {173:647--173:670},
	file = {arXiv Fulltext PDF:/Users/willow/Zotero/storage/UMH2IR8G/Gladshtein et al. - 2024 - Mechanised Hypersafety Proofs about Structured Dat.pdf:application/pdf;arXiv.org Snapshot:/Users/willow/Zotero/storage/BU5ZEJ7R/2404.html:text/html;Full Text PDF:/Users/willow/Zotero/storage/J5LVYWE9/Gladshtein et al. - 2024 - Mechanised Hypersafety Proofs about Structured Dat.pdf:application/pdf},
}

@misc{abdelfattah_interface_2024,
	title = {Interface for {Sparse} {Linear} {Algebra} {Operations}},
	url = {http://arxiv.org/abs/2411.13259},
	doi = {10.48550/arXiv.2411.13259},
	abstract = {The standardization of an interface for dense linear algebra operations in the BLAS standard has enabled interoperability between different linear algebra libraries, thereby boosting the success of scientific computing, in particular in scientific HPC. Despite numerous efforts in the past, the community has not yet agreed on a standardization for sparse linear algebra operations due to numerous reasons. One is the fact that sparse linear algebra objects allow for many different storage formats, and different hardware may favor different storage formats. This makes the definition of a FORTRAN-style all-circumventing interface extremely challenging. Another reason is that opposed to dense linear algebra functionality, in sparse linear algebra, the size of the sparse data structure for the operation result is not always known prior to the information. Furthermore, as opposed to the standardization effort for dense linear algebra, we are late in the technology readiness cycle, and many production-ready software libraries using sparse linear algebra routines have implemented and committed to their own sparse BLAS interface. At the same time, there exists a demand for standardization that would improve interoperability, and sustainability, and allow for easier integration of building blocks. In an inclusive, cross-institutional effort involving numerous academic institutions, US National Labs, and industry, we spent two years designing a hardware-portable interface for basic sparse linear algebra functionality that serves the user needs and is compatible with the different interfaces currently used by different vendors. In this paper, we present a C++ API for sparse linear algebra functionality, discuss the design choices, and detail how software developers preserve a lot of freedom in terms of how to implement functionality behind this API.},
	urldate = {2024-11-26},
	publisher = {arXiv},
	author = {Abdelfattah, Ahmad and Ahrens, Willow and Anzt, Hartwig and Armstrong, Chris and Brock, Ben and Buluc, Aydin and Busato, Federico and Cojean, Terry and Davis, Tim and Demmel, Jim and Dinh, Grace and Gardener, David and Fiala, Jan and Gates, Mark and Haider, Azzam and Imamura, Toshiyuki and Lara, Pedro Valero and Moreira, Jose and Li, Sherry and Luszczek, Piotr and Melichenko, Max and Moeira, Jose and Mokwinski, Yvan and Murray, Riley and Patty, Spencer and Peles, Slaven and Ribizel, Tobias and Riedy, Jason and Rajamanickam, Siva and Sao, Piyush and Shantharam, Manu and Teranishi, Keita and Tomov, Stan and Tsai, Yu-Hsiang and Weichelt, Heiko},
	month = nov,
	year = {2024},
	note = {arXiv:2411.13259},
	keywords = {Computer Science - Mathematical Software},
	file = {Preprint PDF:/Users/willow/Zotero/storage/G9ZTWF2H/Abdelfattah et al. - 2024 - Interface for Sparse Linear Algebra Operations.pdf:application/pdf;Snapshot:/Users/willow/Zotero/storage/ZZV5IEHH/2411.html:text/html},
}
